{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP+3CNKX77QtNOfL6Y20RzZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunaficus/DRL/blob/main/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTYvcD6TdWiP",
        "outputId": "9cd769ff-3dc3-4978-c06e-9c651f098fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'navigating_uncertainty_in_mpp'...\n",
            "remote: Enumerating objects: 12419, done.\u001b[K\n",
            "remote: Counting objects: 100% (619/619), done.\u001b[K\n",
            "remote: Compressing objects: 100% (185/185), done.\u001b[K\n",
            "remote: Total 12419 (delta 435), reused 603 (delta 434), pack-reused 11800 (from 1)\u001b[K\n",
            "Receiving objects: 100% (12419/12419), 578.14 MiB | 33.53 MiB/s, done.\n",
            "Resolving deltas: 100% (8402/8402), done.\n",
            "Updating files: 100% (1357/1357), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OptimalPursuit/navigating_uncertainty_in_mpp.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd navigating_uncertainty_in_mpp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF7BQqIVhch8",
        "outputId": "2434d681-5e8c-4cc5-e8ac-f18c78516615"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'navigating_uncertainty_in_mpp'\n",
            "/content/navigating_uncertainty_in_mpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPyZlSJUhew-",
        "outputId": "41eee2f2-b016-4bf7-e16e-c7d1266660bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rl4co@ git+https://github.com/ai4co/rl4co.git@907d07567bc06813ddbd222a13c49682ff1d1b63 (from -r requirements.txt (line 239))\n",
            "  Cloning https://github.com/ai4co/rl4co.git (to revision 907d07567bc06813ddbd222a13c49682ff1d1b63) to /tmp/pip-install-2puj1b26/rl4co_0049ecce001d416eaa35918c4e5dec75\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ai4co/rl4co.git /tmp/pip-install-2puj1b26/rl4co_0049ecce001d416eaa35918c4e5dec75\n",
            "  Running command git rev-parse -q --verify 'sha^907d07567bc06813ddbd222a13c49682ff1d1b63'\n",
            "  Running command git fetch -q https://github.com/ai4co/rl4co.git 907d07567bc06813ddbd222a13c49682ff1d1b63\n",
            "  Running command git checkout -q 907d07567bc06813ddbd222a13c49682ff1d1b63\n",
            "  Resolved https://github.com/ai4co/rl4co.git to commit 907d07567bc06813ddbd222a13c49682ff1d1b63\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stable_baselines3@ git+https://github.com/DLR-RM/stable-baselines3@6ad6fa55b6e38c8456dd333f71fe45373f66fe90 (from -r requirements.txt (line 272))\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 (to revision 6ad6fa55b6e38c8456dd333f71fe45373f66fe90) to /tmp/pip-install-2puj1b26/stable-baselines3_63a54ab04b174dac802bd29bd94b8f29\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-install-2puj1b26/stable-baselines3_63a54ab04b174dac802bd29bd94b8f29\n",
            "  Running command git rev-parse -q --verify 'sha^6ad6fa55b6e38c8456dd333f71fe45373f66fe90'\n",
            "  Running command git fetch -q https://github.com/DLR-RM/stable-baselines3 6ad6fa55b6e38c8456dd333f71fe45373f66fe90\n",
            "  Running command git checkout -q 6ad6fa55b6e38c8456dd333f71fe45373f66fe90\n",
            "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit 6ad6fa55b6e38c8456dd333f71fe45373f66fe90\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Collecting aiohttp==3.7.4.post0 (from -r requirements.txt (line 2))\n",
            "  Downloading aiohttp-3.7.4.post0.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting alabaster==0.7.16 (from -r requirements.txt (line 3))\n",
            "  Downloading alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting ale-py==0.8.1 (from -r requirements.txt (line 4))\n",
            "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting alembic==1.11.1 (from -r requirements.txt (line 5))\n",
            "  Downloading alembic-1.11.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.9.3)\n",
            "Collecting anyio==4.4.0 (from -r requirements.txt (line 8))\n",
            "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting appdirs==1.4.4 (from -r requirements.txt (line 9))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: argon2-cffi==23.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (23.1.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (21.2.0)\n",
            "Collecting arrow==1.3.0 (from -r requirements.txt (line 12))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting asttokens==3.0.0 (from -r requirements.txt (line 13))\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting async-lru==2.0.4 (from -r requirements.txt (line 14))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting async-timeout==3.0.1 (from -r requirements.txt (line 15))\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting attrs==23.1.0 (from -r requirements.txt (line 16))\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting AutoROM==0.6.1 (from -r requirements.txt (line 17))\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting AutoROM.accept-rom-license==0.6.1 (from -r requirements.txt (line 18))\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Babel==2.15.0 (from -r requirements.txt (line 19))\n",
            "  Downloading Babel-2.15.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting beautifulsoup4==4.12.3 (from -r requirements.txt (line 20))\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting black==24.4.2 (from -r requirements.txt (line 21))\n",
            "  Downloading black-24.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bleach==6.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (6.2.0)\n",
            "Collecting blinker==1.6.2 (from -r requirements.txt (line 23))\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting cached-property==1.5.2 (from -r requirements.txt (line 24))\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting cachetools==5.3.0 (from -r requirements.txt (line 25))\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting certifi==2023.11.17 (from -r requirements.txt (line 26))\n",
            "  Downloading certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting cffi==1.15.1 (from -r requirements.txt (line 27))\n",
            "  Downloading cffi-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting chardet==4.0.0 (from -r requirements.txt (line 28))\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting charset-normalizer==3.1.0 (from -r requirements.txt (line 29))\n",
            "  Downloading charset_normalizer-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
            "Collecting chex==0.1.5 (from -r requirements.txt (line 30))\n",
            "  Downloading chex-0.1.5-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting clarabel==0.9.0 (from -r requirements.txt (line 31))\n",
            "  Downloading clarabel-0.9.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting click==8.1.3 (from -r requirements.txt (line 32))\n",
            "  Downloading click-8.1.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting cloudpickle==2.2.1 (from -r requirements.txt (line 33))\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting cmaes==0.9.1 (from -r requirements.txt (line 34))\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting colorama==0.4.6 (from -r requirements.txt (line 35))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting colorlog==6.7.0 (from -r requirements.txt (line 36))\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting comm==0.2.2 (from -r requirements.txt (line 37))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy==1.0.7 (from -r requirements.txt (line 38))\n",
            "  Downloading contourpy-1.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting coverage==7.6.0 (from -r requirements.txt (line 39))\n",
            "  Downloading coverage-7.6.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cplex==22.1.1.0 (from versions: 20.1.0.5, 22.1.0.1, 22.1.1.1, 22.1.1.2, 22.1.2.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cplex==22.1.1.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cplex==22.1.1.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1WfNSlYiWyL",
        "outputId": "821578d3-6189-4fe0-e8f2-2d4d75f84085"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cplex==22.1.1.1 in /usr/local/lib/python3.11/dist-packages (22.1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py  # Modify based on actual usage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy3Wbqs9idHZ",
        "outputId": "8964524f-445e-4eaf-f955-e05e77a05ccd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchrl/data/replay_buffers/samplers.py:34: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n",
            "  warnings.warn(EXTENSION_WARNING)\n",
            "Running with folder: sac-fr, algorithm type: sac,generalization: False\n",
            "2025-06-03 16:09:22,175 [torchrl][INFO] check_env_specs succeeded!\n",
            "Warm-up: 100% 3/3 [00:04<00:00,  1.50s/it]\n",
            "Episodes:   0% 0/30 [00:00<?, ?it/s]Max Revenue: 1700.6063232421875\n",
            "Episodes:   3% 1/30 [00:01<00:35,  1.21s/it]Max Revenue: 1865.72607421875\n",
            "Episodes:   7% 2/30 [00:02<00:33,  1.21s/it]Max Revenue: 1798.8203125\n",
            "Episodes:  10% 3/30 [00:03<00:32,  1.21s/it]Max Revenue: 1649.8131103515625\n",
            "Episodes:  13% 4/30 [00:04<00:31,  1.20s/it]Max Revenue: 1784.152099609375\n",
            "Episodes:  17% 5/30 [00:06<00:29,  1.20s/it]Max Revenue: 1902.563232421875\n",
            "Episodes:  20% 6/30 [00:07<00:28,  1.21s/it]Max Revenue: 1379.84765625\n",
            "Episodes:  23% 7/30 [00:08<00:28,  1.23s/it]Max Revenue: 1685.802490234375\n",
            "Episodes:  27% 8/30 [00:10<00:30,  1.39s/it]Max Revenue: 1653.673095703125\n",
            "Episodes:  30% 9/30 [00:11<00:29,  1.43s/it]Max Revenue: 1951.238037109375\n",
            "Episodes:  33% 10/30 [00:12<00:27,  1.36s/it]Max Revenue: 1968.203857421875\n",
            "Episodes:  37% 11/30 [00:14<00:24,  1.31s/it]Max Revenue: 1548.932861328125\n",
            "Episodes:  40% 12/30 [00:15<00:23,  1.28s/it]Max Revenue: 2066.649658203125\n",
            "Episodes:  43% 13/30 [00:16<00:21,  1.29s/it]Max Revenue: 1709.462890625\n",
            "Episodes:  47% 14/30 [00:17<00:20,  1.29s/it]Max Revenue: 1992.97021484375\n",
            "Episodes:  50% 15/30 [00:19<00:19,  1.29s/it]Max Revenue: 1552.67578125\n",
            "Episodes:  53% 16/30 [00:20<00:17,  1.26s/it]Max Revenue: 1613.689453125\n",
            "Episodes:  57% 17/30 [00:21<00:17,  1.31s/it]Max Revenue: 1921.493408203125\n",
            "Episodes:  60% 18/30 [00:23<00:16,  1.40s/it]Max Revenue: 1498.53564453125\n",
            "Episodes:  63% 19/30 [00:24<00:14,  1.35s/it]Max Revenue: 1512.250732421875\n",
            "Episodes:  67% 20/30 [00:25<00:13,  1.31s/it]Max Revenue: 1522.262451171875\n",
            "Episodes:  70% 21/30 [00:27<00:11,  1.28s/it]Max Revenue: 1412.5361328125\n",
            "Episodes:  73% 22/30 [00:28<00:09,  1.25s/it]Max Revenue: 1445.6533203125\n",
            "Episodes:  77% 23/30 [00:29<00:08,  1.23s/it]Max Revenue: 1828.492431640625\n",
            "Episodes:  80% 24/30 [00:30<00:07,  1.22s/it]Max Revenue: 1429.09130859375\n",
            "Episodes:  83% 25/30 [00:31<00:06,  1.21s/it]Max Revenue: 1506.420654296875\n",
            "Episodes:  87% 26/30 [00:33<00:04,  1.21s/it]Max Revenue: 1620.449462890625\n",
            "Episodes:  90% 27/30 [00:35<00:04,  1.45s/it]Max Revenue: 1606.10546875\n",
            "Episodes:  93% 28/30 [00:36<00:02,  1.40s/it]Max Revenue: 1732.14794921875\n",
            "Episodes:  97% 29/30 [00:37<00:01,  1.34s/it]Max Revenue: 1734.4298095703125\n",
            "Episodes: 100% 30/30 [00:38<00:00,  1.29s/it]\n",
            "{'total_profit': {'mean': 1245.264892578125, 'median': 1228.2059326171875, 'std': 138.29168701171875, 'min': 924.97265625, 'max': 1556.07421875, 'lb_ci': 1195.7787499301305, 'ub_ci': 1294.7510352261195, 'value': [1305.588623046875, 1382.968505859375, 1311.57421875, 1233.661376953125, 1325.85595703125, 1312.31591796875, 1024.2529296875, 1157.225830078125, 1297.1134033203125, 1420.4759521484375, 1454.0462646484375, 1208.253662109375, 1556.07421875, 1277.64990234375, 1447.9708251953125, 1121.19580078125, 1190.650390625, 1384.1142578125, 1114.17626953125, 1122.490234375, 1157.229736328125, 1145.89501953125, 1128.247314453125, 1365.38916015625, 1098.82861328125, 924.97265625, 1196.78759765625, 1224.000244140625, 1228.2059326171875, 1240.7330322265625]}, 'total_violations': {'mean': 154.78941345214844, 'median': 146.6011199951172, 'std': 35.33403015136719, 'min': 98.27802276611328, 'max': 259.10858154296875, 'lb_ci': 142.14552361189416, 'ub_ci': 167.4333032924027, 'value': [187.03091430664062, 133.3612518310547, 189.67076110839844, 259.10858154296875, 133.75454711914062, 99.50663757324219, 142.527099609375, 180.2518768310547, 127.2529296875, 189.88868713378906, 146.6011199951172, 192.4110107421875, 158.87747192382812, 172.36729431152344, 205.7415771484375, 165.47352600097656, 172.7604522705078, 110.88682556152344, 172.8897247314453, 125.1248779296875, 138.74710083007812, 130.18478393554688, 180.3775634765625, 132.94593811035156, 98.27802276611328, 116.55122375488281, 159.93698120117188, 161.4740447998047, 143.61524963378906, 116.08419799804688]}, 'inference_times': {'mean': 1.2820336818695068, 'median': 1.2011774778366089, 'std': 0.1907365471124649, 'min': 1.169270396232605, 'max': 2.007248878479004, 'lb_ci': 1.2137807291248237, 'ub_ci': 1.35028663461419, 'value': [1.172455072402954, 1.2003473043441772, 1.1898225545883179, 1.1781750917434692, 1.1897531747817993, 1.2105739116668701, 1.2653861045837402, 1.7154953479766846, 1.4939987659454346, 1.2133196592330933, 1.1905168294906616, 1.2091636657714844, 1.3019065856933594, 1.2790510654449463, 1.2653385400772095, 1.1809957027435303, 1.4200496673583984, 1.6127736568450928, 1.2108432054519653, 1.2095623016357422, 1.1951823234558105, 1.169270396232605, 1.1826155185699463, 1.1952455043792725, 1.1810519695281982, 1.2011774778366089, 2.007248878479004, 1.2633912563323975, 1.1805243492126465, 1.175775408744812]}, 'feasible_instance': {'mean': 0.0, 'median': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0, 'lb_ci': 0.0, 'ub_ci': 0.0, 'value': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'demand_violations': {'mean': 150.36978149414062, 'median': 142.52708435058594, 'std': 35.451087951660156, 'min': 84.00837707519531, 'max': 243.30331420898438, 'lb_ci': 137.6840038215189, 'ub_ci': 163.05555916676235, 'value': [187.03091430664062, 131.0871124267578, 187.630859375, 243.30331420898438, 133.75454711914062, 89.35903930664062, 142.52708435058594, 180.25189208984375, 127.25293731689453, 165.74432373046875, 135.74853515625, 192.41102600097656, 124.28556060791016, 171.19772338867188, 201.05654907226562, 165.47354125976562, 172.7604522705078, 84.00837707519531, 172.8897247314453, 125.1248779296875, 138.74710083007812, 130.18478393554688, 180.3775634765625, 132.9459228515625, 98.27802276611328, 116.55122375488281, 159.93698120117188, 161.4740447998047, 143.61524963378906, 116.0842056274414]}, 'capacity_violations': {'mean': 4.419628143310547, 'median': 0.0, 'std': 9.133526802062988, 'min': 0.0, 'max': 34.59192657470703, 'lb_ci': 1.1512971252077078, 'ub_ci': 7.687959161413386, 'value': [0.0, 2.274138927459717, 2.0398898124694824, 15.805269241333008, 0.0, 10.147603988647461, 0.0, 0.0, 0.0, 24.144363403320312, 10.852588653564453, 0.0, 34.59192657470703, 1.1695702075958252, 4.685041427612305, 0.0, 0.0, 26.878433227539062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'stability_violations': {'mean': 0.0, 'median': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0, 'lb_ci': 0.0, 'ub_ci': 0.0, 'value': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'pbs_violations': {'mean': 0.0, 'median': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0, 'lb_ci': 0.0, 'ub_ci': 0.0, 'value': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'max_revenues': {'mean': 0.0, 'median': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0, 'lb_ci': 0.0, 'ub_ci': 0.0, 'value': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#結果分析\n",
        "🔹 一、總利潤（total_profit）\n",
        "---\n",
        "| 指標          | 數值                  |\n",
        "| ----------- | ------------------- |\n",
        "| 平均值（mean）   | 1245.26             |\n",
        "| 中位數（median） | 1228.21             |\n",
        "| 標準差（std）    | 138.29              |\n",
        "| 最大值（max）    | 1556.07             |\n",
        "| 最小值（min）    | 924.97              |\n",
        "| 95% 信賴區間    | \\[1195.78, 1294.75] |\n",
        "\n",
        "🔍 分析：\n",
        "\n",
        "平均與中位數接近，表示利潤分布大致對稱。\n",
        "\n",
        "標準差 138 表示模型有一定的波動，但整體穩定。\n",
        "\n",
        "最大值與最小值差距達 631.1，顯示部分樣本表現特別好或特別差。\n",
        "\n",
        "利潤表現落在預期區間，整體穩定性良好。\n",
        "\n",
        "---\n",
        "\n",
        "🔹 二、違規狀況分析（total_violations + 各子項）\n",
        "---\n",
        "🌐 總違規數 total_violations\n",
        "\n",
        "| 指標     | 數值                         |\n",
        "| ------ | -------------------------- |\n",
        "| 平均值    | **154.79**                 |\n",
        "| 標準差    | 35.33                      |\n",
        "| 占比主要來自 | 需求違規 (`demand_violations`) |\n",
        "\n",
        "📦 需求違規 demand_violations\n",
        "平均： 150.37（佔總違規 97% 以上）\n",
        "\n",
        "顯示大部分違規源自於未能滿足運送需求或過度超載需求。\n",
        "\n",
        "🧱 容量違規 capacity_violations\n",
        "平均： 4.42\n",
        "\n",
        "中位數： 0.0，顯示大多數樣本無容量違規，但有極端值（最高 34.59）造成平均上升。\n",
        "\n",
        "📊 其他違規：穩定性 (stability_violations)、PBS (pbs_violations) 皆為 0。\n",
        "→ 代表模型在船隻穩定性與重心限制方面已完美遵守規則。\n",
        "\n",
        "🔍 總結分析：\n",
        "\n",
        "最大問題來自需求預測與分配，建議優化 需求預測精度與分配策略。\n",
        "\n",
        "容量違規屬於偶發事件，可能出現在特定場景，應可透過後處理修正。\n",
        "\n",
        "---\n",
        "🔹 三、推理時間（inference_times）\n",
        "---\n",
        "| 指標  | 數值     |\n",
        "| --- | ------ |\n",
        "| 平均  | 1.28 秒 |\n",
        "| 最快  | 1.17 秒 |\n",
        "| 最慢  | 2.00 秒 |\n",
        "| 標準差 | 0.19 秒 |\n",
        "\n",
        "🔍 分析：\n",
        "\n",
        "整體推理時間穩定、低延遲（<2秒），適合實務即時部署。\n",
        "\n",
        "有個別案例略高（如 2 秒），但仍在容忍範圍內。\n",
        "\n",
        "---\n",
        "🔹 四、可行性與其他指標\n",
        "---\n",
        "\n",
        "feasible_instance: 全部為 0，表示模型輸出的解皆為「不可完全可行解（至少有一處違規）」。\n",
        "\n",
        "max_revenues: 全為 0，可能代表該欄位未實作或為佔位欄。\n",
        "\n",
        "📌 重要觀察：\n",
        "\n",
        "模型在大多數條件下都能提供可接受解，但「完全無違規」的情形尚未達成。\n",
        "\n",
        "若目標是達到100%可行解（如正式部署需求），建議加入 可行性修正模組（如 Feasibility Projection）或懲罰損失項目。\n",
        "\n",
        "---\n",
        "🔹結論\n",
        "---\n",
        "| 優點                    | 建議改善                           |\n",
        "| --------------------- | ------------------------------ |\n",
        "| ⏱ 快速推理（<2秒）           | 📉 增加可行性達成率（feasible instance） |\n",
        "| 💰 穩定高利潤輸出（均值 > 1200） | 🎯 改善需求違規處理策略                  |\n",
        "| ⚖️ 無穩定性與 PBS 違規       | 🔧 對偶發容量違規做平滑化處理               |\n",
        "\n"
      ],
      "metadata": {
        "id": "cueiDb1TuGna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "一、研究背景與動機\n",
        "---\n",
        "全球超過45%的貨物是透過貨櫃運輸完成，總值高達8.1兆美元，然而貨櫃船的艙位配置（stowage planning）受到載重限制、穩定性、安全與需求變動等多重限制，因此規劃極為複雜。傳統方法難以應對這些不確定因素且運算成本高昂。\n",
        "\n",
        "為解決此問題，本文提出一種結合 深度強化學習（Deep Reinforcement Learning, DRL）與可行性投影機制（feasibility projection） 的方法，專注於貨櫃主配置規劃問題（Master Stowage Planning Problem, MPP），目標為在面對不確定需求下，提升貨櫃艙位使用效率與營收。\n",
        "\n",
        "---\n",
        "二、研究貢獻\n",
        "---\n",
        "🔧 建立真實場域的 MDP 模型：將貨櫃主配置規劃建模為一個 Markov 決策過程，模擬不同港口的動態變化與艙位限制。\n",
        "\n",
        "🧩 引入可微分的可行性投影層（Projection Layers）：包含權重縮放（WS）、策略剪裁（PC）、違規修正（VP）三種方式，有效強化模型對限制條件的學習與滿足能力。\n",
        "\n",
        "⚙️ 提出 Encoder-Decoder 架構的 Actor-Critic 強化學習方法：搭配動態與情境嵌入（embedding）方式，讓模型能前瞻性地判斷未來狀況。\n",
        "\n",
        "📈 實驗證明效能優於傳統方法：包括混合整數規劃（SMIP）與原生強化學習法（PPO、SAC），在可行性與營收表現上均有顯著提升。\n",
        "\n",
        "---\n",
        "三、方法架構概述\n",
        "---\n",
        "為了解決貨櫃主配置規劃問題（MPP）中動作空間複雜、限制條件多且需求不確定的挑戰，本文提出一個結合「深度強化學習（Deep Reinforcement Learning, DRL）」與「可行性投影機制（Feasibility Projection）」的架構，流程如下\n",
        "\n",
        "Cargo Embedding → Encoding →\n",
        "\n",
        "Context / Dynamic Embedding → Actor & Critic\n",
        "\n",
        "動作輸出 → 可行性投影修正\n",
        "\n",
        "評估價值 → 回傳訓練信號更新模型\n",
        "\n",
        "整體方法主要包含三個核心組件：\n",
        "\n",
        "1. Encoder-Decoder 架構（以注意力機制為核心）\n",
        "🔹 Cargo Embedding\n",
        "將每一筆貨櫃資料（包括來源港、目的港、貨櫃大小、重量、合約類型等）轉換為數值特徵向量，再加上位置編碼（Positional Encoding）來保留順序資訊，方便後續模型捕捉時間與空間上下文。\n",
        "\n",
        "🔹 Encoder\n",
        "透過多頭注意力機制（Multi-Head Attention, MHA），將貨櫃特徵進行全局建模，得到代表整體航程需求與結構的潛在表示（Latent Representation）。\n",
        "\n",
        "🔹 Context Embedding 與 Dynamic Embedding\n",
        "Context Embedding 根據當下船艙使用情況 ut 與編碼結果 z，生成上下文向量，幫助政策關注當前的船況與艙位限制。\n",
        "\n",
        "Dynamic Embedding 則基於未來需求變化（qt）與時間步長進行序列建模，捕捉長期需求變化趨勢。\n",
        "\n",
        "🔹 Decoder (Actor-Critic)\n",
        "Actor 根據當前狀態與嵌入資訊，使用注意力指標機制（Pointer Network）輸出行動分布：πθ(x|s)，採樣動作 xt。\n",
        "\n",
        "Critic 為單層或雙層 FFN，用來估算當前狀態的期望價值 V(st)。\n",
        "\n",
        "2. 可行性投影機制（Feasibility Projection Layers）\n",
        "由於 MPP 問題具有明確的線性不等式限制（如：容量限制、穩定性限制、需求限制等），必須確保強化學習輸出的行動能夠落在可行域中。因此作者設計三種可微分的投影方法：\n",
        "\n",
        "🔸 Weighted Scaling (WS)\n",
        "當行動向量總和超過上限（如需求量或 TEU 容量），則按比例縮放，使其剛好符合限制，並保留原始比例。\n",
        "\n",
        "🔸 Policy Clipping (PC)\n",
        "將每個動作元素限制在上下界區間內，類似於 box constraints 處理（element-wise bounding）。\n",
        "\n",
        "🔸 Violation Projection (VP)\n",
        "若行動違反某些約束條件，則透過梯度下降方式將其投影回可行域的近似點，並利用 Jacobian 調整保留 log 機率密度。\n",
        "\n",
        "這些機制可以視為類似 Soft Constraint 的可行性修復策略，使學習過程中的動作不至於因違規而導致不穩定訓練。\n",
        "\n",
        "3. 兩階段馬可夫決策過程設計（Formal MDP 與 Decomposed MDP）\n",
        "為了提高訓練效率，該研究將原始 MDP 分為兩種形式處理：\n",
        "\n",
        "📌 Formal MDP\n",
        "每一港口一次性做出全部艙位分配決策（高維度）\n",
        "\n",
        "動作空間為 |B| × |D| × |K| × |TR|，容易導致學習不穩定\n",
        "\n",
        "📌 Decomposed MDP\n",
        "將一個港口的決策細分為多個小步驟，逐步處理每個 (pol, pod, cargo type)\n",
        "\n",
        "將動作空間降為 |B| × |D|，延長時間步長並提升學習穩定性\n",
        "\n",
        "成本函數僅在港口階段進行評估（sparse reward）\n",
        "\n",
        "✨ 損失函數與訓練方式\n",
        "強化學習採用 Actor-Critic 框架，具體損失函數如下：\n",
        "\n",
        "Actor Loss（策略最大化 + 可行性懲罰）\n",
        "Critic Loss（狀態價值函數的 MSE）\n",
        "Feasibility Loss\n",
        "\n",
        "---\n",
        "四、實驗設計與結果\n",
        "---\n",
        "測試項目：\n",
        "🚢 載重 1000 TEU，4 個港口的航線\n",
        "\n",
        "模擬不確定需求（高/低變異）\n",
        "\n",
        "比較 DRL（SAC/PPO）與 SMIP 方法\n",
        "\n",
        "評估指標：利潤（Ob.）、計算時間、可行性（F.I.）、違規程度（d(PH)）\n",
        "\n",
        "| 方法                | 可行性 (%) | 平均利潤 (\\$)   | 計算時間 (秒)    |\n",
        "| ----------------- | ------- | ----------- | ----------- |\n",
        "| SAC + 投影層 (WS/PC) | 100     | **1494.22** | **13.12**   |\n",
        "| PPO + 投影層 (WS/PC) | 100     | 1471.40     | 13.75       |\n",
        "| 傳統 SMIP-NA        | 100     | 1053.02     | **8434.58** |\n",
        "\n",
        "\n",
        "SAC 與 PPO 在加入投影後皆可保證100%可行性，且獲得最高利潤。\n",
        "\n",
        "相比之下，SMIP-NA 雖能解出解，但計算時間太長，不適用於實務。\n",
        "\n",
        "---\n",
        "五、管理意涵與實務建議\n",
        "---\n",
        "✅ 可行性機制效果佳：權重縮放與投影層能有效取代繁複的 Lagrangian 式懲罰。\n",
        "\n",
        "⚡ 可大幅降低計算成本：投影後 DRL 推理僅需數十秒，適合實務快速調度需求。\n",
        "\n",
        "🔄 對不確定性具適應能力：DRL 模型在需求變異越高時反而表現更佳，具預測與回應能力。\n",
        "\n",
        "📊 可推廣至實務部署：未來實作應重視收集代表性需求數據，以提升模型泛化能力。\n",
        "\n",
        "---\n",
        "六、結論與未來工作\n",
        "---\n",
        "本研究展示了深度強化學習結合可行性投影在貨櫃船配置規劃上的潛力，能即時提供動態決策支援。未來方向包含：\n",
        "\n",
        "擴展模型至更大船隻與更長航線\n",
        "\n",
        "結合真實操作資料進行驗證\n",
        "\n",
        "與其他港口操作（如吊車排程）整合進行聯合最佳化\n",
        "\n"
      ],
      "metadata": {
        "id": "JbZEb8HVsOX5"
      }
    }
  ]
}